{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c9d73bb-e8d5-4aeb-a928-93db9ac6241c"
      },
      "source": [
        "# Transformer boilerplate code + how to use it\n",
        "# https://towardsdatascience.com/a-detailed-guide-to-pytorchs-nn-transformer-module-c80afbc9ffb1\n",
        "##### by Daniel Melchor (dmh672@gmail.com)"
      ],
      "id": "2c9d73bb-e8d5-4aeb-a928-93db9ac6241c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31985af0-d58e-4d01-8432-065537022502"
      },
      "source": [
        "---\n",
        "## Imports"
      ],
      "id": "31985af0-d58e-4d01-8432-065537022502"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "446258e5-7cf2-4a73-8dd7-7b7a43fdd98e",
        "outputId": "47b53fa2-a24f-4b6a-baca-90d30bdb34a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /home/danielmelchor/Documents/CodeProjects/TransformerProgram/venv/lib64/python3.9/site-packages (1.9.0)\n",
            "Requirement already satisfied: numpy in /home/danielmelchor/Documents/CodeProjects/TransformerProgram/venv/lib64/python3.9/site-packages (1.21.0)\n",
            "Requirement already satisfied: matplotlib in /home/danielmelchor/Documents/CodeProjects/TransformerProgram/venv/lib64/python3.9/site-packages (3.4.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /home/danielmelchor/Documents/CodeProjects/TransformerProgram/venv/lib64/python3.9/site-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /home/danielmelchor/Documents/CodeProjects/TransformerProgram/venv/lib64/python3.9/site-packages (from matplotlib) (8.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /home/danielmelchor/Documents/CodeProjects/TransformerProgram/venv/lib/python3.9/site-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/danielmelchor/Documents/CodeProjects/TransformerProgram/venv/lib/python3.9/site-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/danielmelchor/Documents/CodeProjects/TransformerProgram/venv/lib/python3.9/site-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: six in /home/danielmelchor/Documents/CodeProjects/TransformerProgram/venv/lib/python3.9/site-packages (from cycler>=0.10->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: typing-extensions in /home/danielmelchor/Documents/CodeProjects/TransformerProgram/venv/lib/python3.9/site-packages (from torch) (3.10.0.0)\n",
            "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1.3 is available.\n",
            "You should consider upgrading via the '/home/danielmelchor/Documents/CodeProjects/TransformerProgram/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install torch numpy matplotlib"
      ],
      "id": "446258e5-7cf2-4a73-8dd7-7b7a43fdd98e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3539f61f-fe7d-4428-b074-327a883f7f6e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "id": "3539f61f-fe7d-4428-b074-327a883f7f6e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "c72c2ada-2106-4505-82f5-086e518080a5"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, dim_model, dropout_p, max_len):\n",
        "        super().__init__()\n",
        "        # Modified version from: https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
        "        # max_len determines how far the position can have an effect on a token (window)\n",
        "        \n",
        "        # Info\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        \n",
        "        # Encoding - From formula\n",
        "        pos_encoding = torch.zeros(max_len, dim_model)\n",
        "        positions_list = torch.arange(0, max_len, dtype=torch.float).view(-1, 1) # 0, 1, 2, 3, 4, 5\n",
        "        division_term = torch.exp(torch.arange(0, dim_model, 2).float() * (-math.log(10000.0)) / dim_model) # 1000^(2i/dim_model)\n",
        "        \n",
        "        # PE(pos, 2i) = sin(pos/1000^(2i/dim_model))\n",
        "        pos_encoding[:, 0::2] = torch.sin(positions_list * division_term)\n",
        "        \n",
        "        # PE(pos, 2i + 1) = cos(pos/1000^(2i/dim_model))\n",
        "        pos_encoding[:, 1::2] = torch.cos(positions_list * division_term)\n",
        "        \n",
        "        # Saving buffer (same as parameter without gradients needed)\n",
        "        pos_encoding = pos_encoding.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer(\"pos_encoding\",pos_encoding)\n",
        "        \n",
        "    def forward(self, token_embedding: torch.tensor) -> torch.tensor:\n",
        "        # Residual connection + pos encoding\n",
        "        return self.dropout(token_embedding + self.pos_encoding[:token_embedding.size(0), :])"
      ],
      "id": "c72c2ada-2106-4505-82f5-086e518080a5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "588b2729-866c-470a-aca7-6a3c5ea0b192"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "    \"\"\"\n",
        "    Model from \"A detailed guide to Pytorch's nn.Transformer() module.\", by\n",
        "    Daniel Melchor: https://medium.com/p/c80afbc9ffb1/\n",
        "    \"\"\"\n",
        "    # Constructor\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_tokens,\n",
        "        dim_model,\n",
        "        num_heads,\n",
        "        num_encoder_layers,\n",
        "        num_decoder_layers,\n",
        "        dropout_p,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # INFO\n",
        "        self.model_type = \"Transformer\"\n",
        "        self.dim_model = dim_model\n",
        "\n",
        "        # LAYERS\n",
        "        self.positional_encoder = PositionalEncoding(\n",
        "            dim_model=dim_model, dropout_p=dropout_p, max_len=5000\n",
        "        )\n",
        "        self.embedding = nn.Embedding(num_tokens, dim_model)\n",
        "        self.transformer = nn.Transformer(\n",
        "            d_model=dim_model,\n",
        "            nhead=num_heads,\n",
        "            num_encoder_layers=num_encoder_layers,\n",
        "            num_decoder_layers=num_decoder_layers,\n",
        "            dropout=dropout_p,\n",
        "        )\n",
        "        self.out = nn.Linear(dim_model, num_tokens)\n",
        "        \n",
        "    def forward(self, src, tgt, tgt_mask=None, src_pad_mask=None, tgt_pad_mask=None):\n",
        "        # Src size must be (batch_size, src sequence length)\n",
        "        # Tgt size must be (batch_size, tgt sequence length)\n",
        "\n",
        "        # Embedding + positional encoding - Out size = (batch_size, sequence length, dim_model)\n",
        "        src = self.embedding(src) * math.sqrt(self.dim_model)\n",
        "        tgt = self.embedding(tgt) * math.sqrt(self.dim_model)\n",
        "        src = self.positional_encoder(src)\n",
        "        tgt = self.positional_encoder(tgt)\n",
        "        \n",
        "        # We could use the parameter batch_first=True, but our KDL version doesn't support it yet, so we permute\n",
        "        # to obtain size (sequence length, batch_size, dim_model),\n",
        "        src = src.permute(1,0,2)\n",
        "        tgt = tgt.permute(1,0,2)\n",
        "\n",
        "        # Transformer blocks - Out size = (sequence length, batch_size, num_tokens)\n",
        "        transformer_out = self.transformer(src, tgt, tgt_mask=tgt_mask, src_key_padding_mask=src_pad_mask, tgt_key_padding_mask=tgt_pad_mask)\n",
        "        out = self.out(transformer_out)\n",
        "        \n",
        "        return out\n",
        "      \n",
        "    def get_tgt_mask(self, size) -> torch.tensor:\n",
        "        # Generates a squeare matrix where the each row allows one word more to be seen\n",
        "        mask = torch.tril(torch.ones(size, size) == 1) # Lower triangular matrix\n",
        "        mask = mask.float()\n",
        "        mask = mask.masked_fill(mask == 0, float('-inf')) # Convert zeros to -inf\n",
        "        mask = mask.masked_fill(mask == 1, float(0.0)) # Convert ones to 0\n",
        "        \n",
        "        # EX for size=5:\n",
        "        # [[0., -inf, -inf, -inf, -inf],\n",
        "        #  [0.,   0., -inf, -inf, -inf],\n",
        "        #  [0.,   0.,   0., -inf, -inf],\n",
        "        #  [0.,   0.,   0.,   0., -inf],\n",
        "        #  [0.,   0.,   0.,   0.,   0.]]\n",
        "        \n",
        "        return mask\n",
        "    \n",
        "    def create_pad_mask(self, matrix: torch.tensor, pad_token: int) -> torch.tensor:\n",
        "        # If matrix = [1,2,3,0,0,0] where pad_token=0, the result mask is\n",
        "        # [False, False, False, True, True, True]\n",
        "        return (matrix == pad_token)"
      ],
      "id": "588b2729-866c-470a-aca7-6a3c5ea0b192"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8ac39c4a-ab17-4487-a1ab-2b107e880574",
        "outputId": "c794131d-47ef-466a-df41-4620f58dcb6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "562 batches of size 16\n",
            "187 batches of size 16\n"
          ]
        }
      ],
      "source": [
        "def generate_random_data(n):\n",
        "    SOS_token = np.array([2])\n",
        "    EOS_token = np.array([3])\n",
        "    length = 8\n",
        "\n",
        "    data = []\n",
        "\n",
        "    # 1,1,1,1,1,1 -> 1,1,1,1,1\n",
        "    for i in range(n // 3):\n",
        "        X = np.concatenate((SOS_token, np.ones(length), EOS_token))\n",
        "        y = np.concatenate((SOS_token, np.ones(length), EOS_token))\n",
        "        data.append([X, y])\n",
        "\n",
        "    # 0,0,0,0 -> 0,0,0,0\n",
        "    for i in range(n // 3):\n",
        "        X = np.concatenate((SOS_token, np.zeros(length), EOS_token))\n",
        "        y = np.concatenate((SOS_token, np.zeros(length), EOS_token))\n",
        "        data.append([X, y])\n",
        "\n",
        "    # 1,0,1,0 -> 1,0,1,0,1\n",
        "    for i in range(n // 3):\n",
        "        X = np.zeros(length)\n",
        "        start = random.randint(0, 1)\n",
        "\n",
        "        X[start::2] = 1\n",
        "\n",
        "        y = np.zeros(length)\n",
        "        if X[-1] == 0:\n",
        "            y[::2] = 1\n",
        "        else:\n",
        "            y[1::2] = 1\n",
        "\n",
        "        X = np.concatenate((SOS_token, X, EOS_token))\n",
        "        y = np.concatenate((SOS_token, y, EOS_token))\n",
        "\n",
        "        data.append([X, y])\n",
        "\n",
        "    np.random.shuffle(data)\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "def batchify_data(data, batch_size=16, padding=False, padding_token=-1):\n",
        "    batches = []\n",
        "    for idx in range(0, len(data), batch_size):\n",
        "        # We make sure we dont get the last bit if its not batch_size size\n",
        "        if idx + batch_size < len(data):\n",
        "            # Here you would need to get the max length of the batch,\n",
        "            # and normalize the length with the PAD token.\n",
        "            if padding:\n",
        "                max_batch_length = 0\n",
        "\n",
        "                # Get longest sentence in batch\n",
        "                for seq in data[idx : idx + batch_size]:\n",
        "                    if len(seq) > max_batch_length:\n",
        "                        max_batch_length = len(seq)\n",
        "\n",
        "                # Append X padding tokens until it reaches the max length\n",
        "                for seq_idx in range(batch_size):\n",
        "                    remaining_length = max_bath_length - len(data[idx + seq_idx])\n",
        "                    data[idx + seq_idx] += [padding_token] * remaining_length\n",
        "\n",
        "            batches.append(np.array(data[idx : idx + batch_size]).astype(np.int64))\n",
        "\n",
        "    print(f\"{len(batches)} batches of size {batch_size}\")\n",
        "\n",
        "    return batches\n",
        "\n",
        "\n",
        "train_data = generate_random_data(9000)\n",
        "val_data = generate_random_data(3000)\n",
        "\n",
        "train_dataloader = batchify_data(train_data)\n",
        "val_dataloader = batchify_data(val_data)"
      ],
      "id": "8ac39c4a-ab17-4487-a1ab-2b107e880574"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4d04a60a-f013-4eda-b056-fc9bb1b1ea79"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = Transformer(\n",
        "    num_tokens=4, dim_model=8, num_heads=2, num_encoder_layers=3, num_decoder_layers=3, dropout_p=0.1\n",
        ").to(device)\n",
        "opt = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "id": "4d04a60a-f013-4eda-b056-fc9bb1b1ea79"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7bc6949f-2d59-44c3-8198-037e115106aa"
      },
      "outputs": [],
      "source": [
        "def train_loop(model, opt, loss_fn, dataloader):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    \n",
        "    for batch in dataloader:\n",
        "        X, y = batch[:, 0], batch[:, 1]\n",
        "        X, y = torch.tensor(X).to(device), torch.tensor(y).to(device)\n",
        "\n",
        "        # Now we shift the tgt by one so with the <SOS> we predict the token at pos 1\n",
        "        y_input = y[:,:-1]\n",
        "        y_expected = y[:,1:]\n",
        "        \n",
        "        # Get mask to mask out the next words\n",
        "        sequence_length = y_input.size(1)\n",
        "        tgt_mask = model.get_tgt_mask(sequence_length).to(device)\n",
        "\n",
        "        # Standard training except we pass in y_input and tgt_mask\n",
        "        pred = model(X, y_input, tgt_mask)\n",
        "\n",
        "        # Permute pred to have batch size first again\n",
        "        pred = pred.permute(1, 2, 0)      \n",
        "        loss = loss_fn(pred, y_expected)\n",
        "\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "    \n",
        "        total_loss += loss.detach().item()\n",
        "        \n",
        "    return total_loss / len(dataloader)"
      ],
      "id": "7bc6949f-2d59-44c3-8198-037e115106aa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "c23630c9-ce84-4996-8d8c-ff7919303331"
      },
      "outputs": [],
      "source": [
        "def validation_loop(model, loss_fn, dataloader):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            X, y = batch[:, 0], batch[:, 1]\n",
        "            X, y = torch.tensor(X, dtype=torch.long, device=device), torch.tensor(y, dtype=torch.long, device=device)\n",
        "\n",
        "            # Now we shift the tgt by one so with the <SOS> we predict the token at pos 1\n",
        "            y_input = y[:,:-1]\n",
        "            y_expected = y[:,1:]\n",
        "            \n",
        "            # Get mask to mask out the next words\n",
        "            sequence_length = y_input.size(1)\n",
        "            tgt_mask = model.get_tgt_mask(sequence_length).to(device)\n",
        "\n",
        "            # Standard training except we pass in y_input and src_mask\n",
        "            pred = model(X, y_input, tgt_mask)\n",
        "\n",
        "            # Permute pred to have batch size first again\n",
        "            pred = pred.permute(1, 2, 0)      \n",
        "            loss = loss_fn(pred, y_expected)\n",
        "            total_loss += loss.detach().item()\n",
        "        \n",
        "    return total_loss / len(dataloader)"
      ],
      "id": "c23630c9-ce84-4996-8d8c-ff7919303331"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5e57ba93-cc8f-4b12-870f-6aed4dce94ab",
        "outputId": "d6adfda6-cc4d-434c-f052-4069186269fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training and validating model\n",
            "------------------------- Epoch 1 -------------------------\n",
            "Training loss: 0.7328\n",
            "Validation loss: 0.6211\n",
            "\n",
            "------------------------- Epoch 2 -------------------------\n",
            "Training loss: 0.6202\n",
            "Validation loss: 0.5866\n",
            "\n",
            "------------------------- Epoch 3 -------------------------\n",
            "Training loss: 0.5773\n",
            "Validation loss: 0.4305\n",
            "\n",
            "------------------------- Epoch 4 -------------------------\n",
            "Training loss: 0.4359\n",
            "Validation loss: 0.3976\n",
            "\n",
            "------------------------- Epoch 5 -------------------------\n",
            "Training loss: 0.4140\n",
            "Validation loss: 0.3888\n",
            "\n",
            "------------------------- Epoch 6 -------------------------\n",
            "Training loss: 0.4003\n",
            "Validation loss: 0.3762\n",
            "\n",
            "------------------------- Epoch 7 -------------------------\n",
            "Training loss: 0.3876\n",
            "Validation loss: 0.3610\n",
            "\n",
            "------------------------- Epoch 8 -------------------------\n",
            "Training loss: 0.3673\n",
            "Validation loss: 0.3163\n",
            "\n",
            "------------------------- Epoch 9 -------------------------\n",
            "Training loss: 0.3332\n",
            "Validation loss: 0.2678\n",
            "\n",
            "------------------------- Epoch 10 -------------------------\n",
            "Training loss: 0.3028\n",
            "Validation loss: 0.2297\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def fit(model, opt, loss_fn, train_dataloader, val_dataloader, epochs):\n",
        "    # Used for plotting later on\n",
        "    train_loss_list, validation_loss_list = [], []\n",
        "    \n",
        "    print(\"Training and validating model\")\n",
        "    for epoch in range(epochs):\n",
        "        print(\"-\"*25, f\"Epoch {epoch + 1}\",\"-\"*25)\n",
        "        \n",
        "        train_loss = train_loop(model, opt, loss_fn, train_dataloader)\n",
        "        train_loss_list += [train_loss]\n",
        "        \n",
        "        validation_loss = validation_loop(model, loss_fn, val_dataloader)\n",
        "        validation_loss_list += [validation_loss]\n",
        "        \n",
        "        print(f\"Training loss: {train_loss:.4f}\")\n",
        "        print(f\"Validation loss: {validation_loss:.4f}\")\n",
        "        print()\n",
        "        \n",
        "    return train_loss_list, validation_loss_list\n",
        "    \n",
        "train_loss_list, validation_loss_list = fit(model, opt, loss_fn, train_dataloader, val_dataloader, 10)"
      ],
      "id": "5e57ba93-cc8f-4b12-870f-6aed4dce94ab"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "40f805ad-7748-4785-9066-c5500287a4af",
        "outputId": "1083e897-007f-4401-8e17-c966a568c642"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(train_loss_list, label = \"Train loss\")\n",
        "plt.plot(validation_loss_list, label = \"Validation loss\")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss vs Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "40f805ad-7748-4785-9066-c5500287a4af"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5df24c30-15b0-471a-ac4d-a0975fbc6a7d",
        "outputId": "e95e4691-8051-4fd5-f858-a46661925555"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example 0\n",
            "Input: [0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Continuation: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "Example 1\n",
            "Input: [1, 1, 1, 1, 1, 1, 1, 1]\n",
            "Continuation: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "\n",
            "Example 2\n",
            "Input: [1, 0, 1, 0, 1, 0, 1, 0]\n",
            "Continuation: [1, 0, 1, 0, 1, 0, 1, 0, 1, 0]\n",
            "\n",
            "Example 3\n",
            "Input: [0, 1, 0, 1, 0, 1, 0, 1]\n",
            "Continuation: [1, 0, 1, 0, 1, 0, 1, 0, 1, 0]\n",
            "\n",
            "Example 4\n",
            "Input: [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]\n",
            "Continuation: [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]\n",
            "\n",
            "Example 5\n",
            "Input: [0, 1]\n",
            "Continuation: [1, 0, 1, 0, 1, 0, 1, 0, 1, 0]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def predict(model, input_sequence, max_length=15, SOS_token=2, EOS_token=3):\n",
        "    model.eval()\n",
        "    \n",
        "    y_input = torch.tensor([[SOS_token]], dtype=torch.long, device=device)\n",
        "\n",
        "    num_tokens = len(input_sequence[0])\n",
        "\n",
        "    for _ in range(max_length):\n",
        "        # Get source mask\n",
        "        tgt_mask = model.get_tgt_mask(y_input.size(1)).to(device)\n",
        "        \n",
        "        pred = model(input_sequence, y_input, tgt_mask)\n",
        "        \n",
        "        next_item = pred.topk(1)[1].view(-1)[-1].item() # num with highest probability\n",
        "        next_item = torch.tensor([[next_item]], device=device)\n",
        "\n",
        "        # Concatenate previous input with predicted best word\n",
        "        y_input = torch.cat((y_input, next_item), dim=1)\n",
        "\n",
        "        # Stop if model predicts end of sentence\n",
        "        if next_item.view(-1).item() == EOS_token:\n",
        "            break\n",
        "\n",
        "    return y_input.view(-1).tolist()\n",
        "  \n",
        "  \n",
        "# Here we test some examples to observe how the model predicts\n",
        "examples = [\n",
        "    torch.tensor([[2, 0, 0, 0, 0, 0, 0, 0, 0, 3]], dtype=torch.long, device=device),\n",
        "    torch.tensor([[2, 1, 1, 1, 1, 1, 1, 1, 1, 3]], dtype=torch.long, device=device),\n",
        "    torch.tensor([[2, 1, 0, 1, 0, 1, 0, 1, 0, 3]], dtype=torch.long, device=device),\n",
        "    torch.tensor([[2, 0, 1, 0, 1, 0, 1, 0, 1, 3]], dtype=torch.long, device=device),\n",
        "    torch.tensor([[2, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 3]], dtype=torch.long, device=device),\n",
        "    torch.tensor([[2, 0, 1, 3]], dtype=torch.long, device=device)\n",
        "]\n",
        "\n",
        "for idx, example in enumerate(examples):\n",
        "    result = predict(model, example)\n",
        "    print(f\"Example {idx}\")\n",
        "    print(f\"Input: {example.view(-1).tolist()[1:-1]}\")\n",
        "    print(f\"Continuation: {result[1:-1]}\")\n",
        "    print()"
      ],
      "id": "5df24c30-15b0-471a-ac4d-a0975fbc6a7d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RBpKjFT93Lpr"
      },
      "outputs": [],
      "source": [
        ""
      ],
      "id": "RBpKjFT93Lpr"
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "example_use.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
